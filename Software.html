<!DOCTYPE html>
<html style="font-size: 16px;" lang="en"><head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta charset="utf-8">
    <meta name="keywords" content="">
    <meta name="description" content="">
    <title>Software</title>
    <link rel="stylesheet" href="nicepage.css" media="screen">
<link rel="stylesheet" href="Software.css" media="screen">
    <script class="u-script" type="text/javascript" src="jquery.js" defer=""></script>
    <script class="u-script" type="text/javascript" src="nicepage.js" defer=""></script>
    <meta name="generator" content="Nicepage 7.1.0, nicepage.com">
    <link id="u-theme-google-font" rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:100,100i,300,300i,400,400i,500,500i,700,700i,900,900i|Open+Sans:300,300i,400,400i,500,500i,600,600i,700,700i,800,800i">
    <link id="u-page-google-font" rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:300,300i,400,400i,500,500i,700,700i">
    
    
    
    
    
    
    
    
    
    <script type="application/ld+json">{
		"@context": "http://schema.org",
		"@type": "Organization",
		"name": "LAD Robot",
		"logo": "images/pie.jpg"
}</script>
    <meta name="theme-color" content="#478ac9">
    <meta property="og:title" content="Software">
    <meta property="og:description" content="">
    <meta property="og:type" content="website">
  <meta data-intl-tel-input-cdn-path="intlTelInput/"></head>
  <body data-path-to-root="./" data-include-products="false" class="u-body u-xl-mode" data-lang="en"><header class="u-border-5 u-border-no-left u-border-no-right u-border-no-top u-border-palette-1-base u-clearfix u-header u-valign-middle u-white u-header" id="sec-dcbe"><nav class="u-menu u-menu-one-level u-offcanvas u-menu-1">
        <div class="menu-collapse u-custom-font u-font-ubuntu" style="font-size: 1.25rem; letter-spacing: 0px;">
          <a class="u-button-style u-custom-left-right-menu-spacing u-custom-padding-bottom u-custom-top-bottom-menu-spacing u-hamburger-link u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="#">
            <svg class="u-svg-link" viewBox="0 0 24 24"><use xlink:href="#menu-hamburger"></use></svg>
            <svg class="u-svg-content" version="1.1" id="menu-hamburger" viewBox="0 0 16 16" x="0px" y="0px" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg"><g><rect y="1" width="16" height="2"></rect><rect y="7" width="16" height="2"></rect><rect y="13" width="16" height="2"></rect>
</g></svg>
          </a>
        </div>
        <div class="u-custom-menu u-nav-container">
          <ul class="u-custom-font u-font-ubuntu u-nav u-unstyled u-nav-1"><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="./" style="padding: 10px 20px;">Home</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="About.html" style="padding: 10px 20px;">About</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="Sprint-Overviews.html" style="padding: 10px 20px;">Sprint Overviews</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="System-Overview.html" style="padding: 10px 20px;">System Overview</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="Bill-of-Materials.html" style="padding: 10px 20px;">Bill of Materials</a>
</li></ul>
        </div>
        <div class="u-custom-menu u-nav-container-collapse">
          <div class="u-black u-container-style u-inner-container-layout u-opacity u-opacity-95 u-sidenav">
            <div class="u-inner-container-layout u-sidenav-overflow">
              <div class="u-menu-close"></div>
              <ul class="u-align-center u-nav u-popupmenu-items u-unstyled u-nav-2"><li class="u-nav-item"><a class="u-button-style u-nav-link" href="./">Home</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link" href="About.html">About</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link" href="Sprint-Overviews.html">Sprint Overviews</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link" href="System-Overview.html">System Overview</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link" href="Bill-of-Materials.html">Bill of Materials</a>
</li></ul>
            </div>
          </div>
          <div class="u-black u-menu-overlay u-opacity u-opacity-70"></div>
        </div>
      </nav><a href="./" class="u-image u-logo u-image-1" data-image-width="612" data-image-height="534" title="Home">
        <img src="images/pie.jpg" class="u-logo-image u-logo-image-1">
      </a></header>
    <section class="u-clearfix u-section-1" id="sec-b649">
      <div class="u-clearfix u-sheet u-sheet-1">
        <h1 class="u-custom-font u-font-ubuntu u-text u-text-default u-title u-text-1">Software</h1>
        <p class="u-align-center u-custom-font u-font-ubuntu u-text u-text-default u-text-2">The software inside L.A.D has 3 main goals: determining the angles of the user, moving the servos, and controlling the LEDs. As everything was run on the main "brain" (the Raspberry Pi), we did not have any firmware in this project.</p>
        <div class="u-border-3 u-border-grey-dark-1 u-line u-line-horizontal u-line-1"></div>
      </div>
    </section>
    <section class="u-clearfix u-section-2" id="sec-c182">
      <div class="u-clearfix u-sheet u-sheet-1">
        <img class="u-border-5 u-border-grey-75 u-image u-image-contain u-image-default u-image-1" src="images/image15.png" alt="" data-image-width="801" data-image-height="324">
        <p class="u-custom-font u-font-ubuntu u-text u-text-default u-text-1">Fig. 1</p>
        <p class="u-align-center u-custom-font u-font-ubuntu u-text u-text-default u-text-2">Fig. 1 above shows the software pipeline we developed for L.A.D. The Raspberry Pi camera takes in video input showing the user, then runs the MediaPipe pose detection model ​to find all of the landmarks we needed to calculate the angles of the user's arms. Once we have the landmarks, we ensure that the user is in frame, meaning that all 6 of the landmarks we need are in view of the camera, and turns the LEDs the corresponding color (green if the user is in frame, red if not). If the user is in frame, the model will calculate the angles of their arms, and send those angles to the servos, allowing L.A.D. to mimic the user.</p>
      </div>
    </section>
    <section class="u-clearfix u-white u-section-3" id="sec-1013">
      <div class="u-clearfix u-sheet u-valign-top u-sheet-1">
        <div class="custom-expanded u-border-5 u-border-black u-container-style u-group u-palette-1-light-3 u-radius u-group-1">
          <div class="u-container-layout u-container-layout-1">
            <h2 class="u-custom-font u-font-ubuntu u-text u-text-default u-text-1">Pose Detection </h2>
            <p class="u-align-center u-custom-font u-font-ubuntu u-text u-text-default u-text-2">To calculate our angles, we need to be able to find certain points on the users body - namely, the locations of their wrists, elbows, and shoulders​. We chose to use MediaPipe Pose, a powerful pose detection model, from Google's MediaPipe ML model library, to achieve this. </p>
            <img class="u-image u-image-contain u-image-default u-image-1" src="images/image16.png" alt="" data-image-width="383" data-image-height="459">
            <p class="u-align-center u-custom-font u-font-ubuntu u-text u-text-default u-text-3">Fig. 2</p>
            <p class="u-align-center u-custom-font u-font-ubuntu u-text u-text-default u-text-4">As seen in Fig. 2 above, MediaPipe Pose takes in a video input and finds 32 landmarks in the user's face, hands, and body. For our purposes, we only needed landmarks 11-16.&nbsp;</p>
          </div>
        </div>
        <div class="custom-expanded u-align-center u-border-5 u-border-black u-container-align-center u-container-style u-group u-palette-1-light-3 u-radius u-group-2">
          <div class="u-container-layout u-container-layout-2">
            <h2 class="u-custom-font u-font-ubuntu u-text u-text-default u-text-5">User In Frame Detection</h2>
            <p class="u-custom-font u-font-ubuntu u-text u-text-6">We wanted to make sure that L.A.D would only move when the user was fully in frame and all of the necessary landmarks were visible, as to not cause any confusion when calculating angles.<br>&nbsp;<br>Each landmark has a visibility parameter, which defines how well the model can see the landmark on a scale of 0-1. We looked at each of the 6 landmarks that we needed for our script and checked that their visibility scores were above 0.9 - a threshold value we found through testing. If all 6 landmarks were classified as visible, the user was considered in frame. If any landmark was below the threshold, the user was considered out of frame.&nbsp;<br>
              <br>The Raspberry Pi camera module that we were using doesn't have a very large field of view, which means that it's important for us to be able to communicate to the user when they are in frame as to allow them to more easily correct their positioning. To do this, we decided to use LEDs as a visual marker - turning them red when the user was not in position, and green when they were.&nbsp;
            </p>
            <img class="u-image u-image-default u-image-2" src="images/image17.png" alt="" data-image-width="395" data-image-height="413">
            <img class="u-image u-image-default u-image-3" src="images/image18.png" alt="" data-image-width="470" data-image-height="466">
            <p class="u-custom-font u-font-ubuntu u-text u-text-7">
              <span style="font-size: 1rem;">Fig. 3</span>
              <br>
              <span style="font-size: 1rem;">User out of frame </span>
            </p>
            <p class="u-custom-font u-font-ubuntu u-text u-text-8">
              <span style="font-size: 1rem;">Fig. 4</span>
              <br>
              <span style="font-size: 1rem;">User in frame </span>
            </p>
          </div>
        </div>
      </div>
    </section>
    <section class="u-clearfix u-section-4" id="sec-5f04">
      <div class="u-clearfix u-sheet u-valign-middle u-sheet-1">
        <div class="u-border-5 u-border-grey-75 u-container-style u-expanded-width u-grey-5 u-group u-radius u-group-1">
          <div class="u-container-layout u-container-layout-1">
            <h2 class="u-custom-font u-font-ubuntu u-text u-text-default u-text-1">Angle Calculations</h2>
            <img class="u-image u-image-default u-preserve-proportions u-image-1" src="images/image19.png" alt="" data-image-width="240" data-image-height="224">
            <p class="u-align-center u-custom-font u-font-ubuntu u-text u-text-2">
              <br>
              <br>
              <br>Once we had the landmarks from the MediaPipe model, we needed to calculate the angles of the user's arms. The two angles we needed for each arm were the shoulder's angle in relation to the torso, and the inner angle between the forearm and the bicep. These angles are shown to the right in Fig. 5.<br>
              <br>
              <br>
              <br>
              <br>
              <br>
              <br>
              <br>
              <br>
              <br>
              <br>We used the numpy library's arctan2 function to find these needed angles. The base form for all of these calculations was theta = arctan2((y1-y2) / (x1-x2)), which can be seen graphically in Fig. 6 to the right. We then had to modify some angles for the servos to be able to properly use them, or add a third comparison point - to see these more specific angle calculations, see our GitHub repository below.
            </p>
            <p class="u-align-center u-custom-font u-font-ubuntu u-text u-text-default u-text-3">Fig. 5</p>
            <img class="u-image u-image-default u-preserve-proportions u-image-2" src="images/image20.png" alt="" data-image-width="245" data-image-height="224">
            <p class="u-align-center u-custom-font u-font-ubuntu u-text u-text-default u-text-4">Fig. 6</p>
          </div>
        </div>
      </div>
    </section>
    <section class="u-clearfix u-white u-section-5" id="carousel_2940">
      <div class="u-clearfix u-sheet u-sheet-1">
        <div class="custom-expanded u-border-5 u-border-black u-container-style u-group u-palette-1-light-3 u-radius u-group-1">
          <div class="u-container-layout u-container-layout-1">
            <h2 class="u-custom-font u-font-ubuntu u-text u-text-default u-text-1">Servo Control</h2>
            <p class="u-align-center u-custom-font u-font-ubuntu u-text u-text-default u-text-2">We used the Adafruit 16-Channel PWM / Servo HAT to control our servos, so we decided to also use the built-in library for the software. This meant that we first had to install the Adafruit_Blinka library that allowed us to use CircuitPython on the Pi, then install the servokit library.&nbsp;<br>
              <br>Controlling the servos ended up being very simple - the servo would be given an angle from 0-180 degrees, then move to that angle. The main difficulty we faced was taking into account the orientation of the servos, since with this library, we were unable to give the servos angles that were negative or greater than 180 degrees. This meant that we had to adjust the way the angles were calculated in the code such that the servos would be rotating in the correct direction. This often entailed subtracting the angle that was calculated from 180 so that the direction of rotation was flipped - 0 would become 180 and 180 would become 0.
            </p>
          </div>
        </div>
        <div class="custom-expanded u-align-center u-border-5 u-border-black u-container-align-center u-container-style u-group u-palette-1-light-3 u-radius u-group-2">
          <div class="u-container-layout u-container-layout-2">
            <h2 class="u-custom-font u-font-ubuntu u-text u-text-default u-text-3">LED Control</h2>
            <p class="u-custom-font u-font-ubuntu u-text u-text-4">We used WS2812B LEDs, which meant that using Adafruit's NeoPixel library was the smartest move, especially since we had previously installed CircuitPython and Adafruit_Blinka, both of which are necessary for NeoPixel usage, for the servo control.&nbsp;<br>
              <br>We connected the LEDs to the Raspberry Pi directly with a GPIO pin, and placed them around the bottom of the head and in the eye of L.A.D. The LEDs have RGB capabilites, so although we only used them to turn green or red when the user is in or out of frame, there are many more possibilities for color combinations.&nbsp;
            </p>
          </div>
        </div>
      </div>
    </section>
    <section class="u-clearfix u-section-6" id="carousel_ecc3">
      <div class="u-clearfix u-sheet u-valign-middle u-sheet-1">
        <div class="u-border-5 u-border-grey-75 u-container-style u-expanded-width u-grey-5 u-group u-radius u-group-1">
          <div class="u-container-layout u-container-layout-1">
            <h2 class="u-custom-font u-font-ubuntu u-text u-text-default u-text-1">3D Pose Estimation</h2>
            <p class="u-align-center u-custom-font u-font-ubuntu u-text u-text-default u-text-2">One of our stretch goals for this project was to be able to mimic motions in 3D rather than 2D space. In the end, we were only able to achieve 2D motion on the software side - on the xy plane as seen in Fig. 7 below - but we felt it would be relevant to explain our attempts nonetheless.</p>
            <img class="u-image u-image-contain u-image-default u-image-1" src="images/image23.png" alt="" data-image-width="344" data-image-height="305">
            <p class="u-align-center u-custom-font u-font-ubuntu u-text u-text-3">Fig. 7<br>The reference frame we were using - the body of the user is on the x and y axes while arms reaching in front or behind the user would be moving in the z axis.
            </p>
            <img class="u-image u-image-contain u-image-default u-image-2" src="images/image22.png" alt="" data-image-width="802" data-image-height="293">
            <p class="u-align-center u-custom-font u-font-ubuntu u-text u-text-4">Fig. 8 </p>
            <p class="u-align-center u-custom-font u-font-ubuntu u-text u-text-5">Fig. 8 above shows the different movements we were trying to achieve. XY movement is the standard movement that we were able to achieve in the end - arms moving in plane with the rest of the body. YZ movement is when the arm moves up and down in front of the body, and XZ movement is when the arm moves side to side in front of the body.&nbsp;<br>
              <br>When trying to calculate these angles, we attempted to use the z-coordinate that MediaPipe provides for each landmark alongside the x and y coordinates. However, we ran into a lot of issues when trying this.&nbsp;Mediapipe’s pose detection model doesn’t work as well with z coordinates (depth) as x and y, which makes sense because we only used one camera, which makes depth difficult to estimate. This means the z position estimates tended to vary more and jitter around more than the x and y estimates.&nbsp;
            </p>
            <p class="u-align-center u-custom-font u-font-ubuntu u-text u-text-6">We also noticed a few consistent problems with the model’s z coordinate estimation.&nbsp;When you hold your arm straight out to the side and bend your elbow so your forearm goes inward, the model’s predicted elbow z position inexplicably moves forward, despite clearly staying in place in reality. Also, when testing the shoulder xz movement (holding your arm straight out to the side and moving it forward so that you are pointing straight forwards), we found that the z coordinate didn’t change evenly as we moved our arm forward, which led to L.A.D’s arm being in the wrong z position for some arm positions.&nbsp;<br>
              <br>We also had some problems with L.A.D flipping out occasionally when we tested it in 3D, perhaps due to occasional large errors in position detection or perhaps due to thinking that the person was no longer visible and shutting off because of a low visibility rate for some points on the arm.<br>
              <br>Because of these issues, we were unable to properly implement 3D pose detection for our final product. Below is a video of us testing this 3D detection on L.A.D, where the issues we described above can be clearly seen.
            </p>
            <p class="u-custom-font u-font-ubuntu u-text u-text-default u-text-7"></p>
            <p class="u-custom-font u-font-ubuntu u-text u-text-default u-text-8"></p>
            <div class="custom-expanded u-uploaded-video u-video u-video-contain u-video-1">
              <div class="embed-responsive">
                <video class="embed-responsive-item" data-autoplay="1" loop="" muted="1" controls="" autoplay="autoplay" playsinline="">
                  <source src="files/softvid.mp4" type="video/mp4">
                  <p>Your browser does not support HTML5 video.</p>
                </video>
              </div>
            </div>
            <p class="u-custom-font u-font-ubuntu u-text u-text-default u-text-9"></p>
          </div>
        </div>
      </div>
    </section>
    <section class="u-clearfix u-white u-section-7" id="carousel_7d69">
      <div class="u-clearfix u-sheet u-sheet-1">
        <div class="u-align-center u-border-5 u-border-black u-container-align-center u-container-style u-expanded-width u-group u-palette-1-light-3 u-radius u-group-1">
          <div class="u-container-layout u-container-layout-1">
            <h2 class="u-custom-font u-font-ubuntu u-text u-text-1">External Software Dependencies</h2>
            <p class="u-custom-font u-font-ubuntu u-text u-text-2">The main external software dependencies are listed below. For a complete list of versions, please look at requirements.txt in the GitHub repository.&nbsp;<br>
            </p>
            <p class="u-custom-font u-font-ubuntu u-text u-text-3"> OpenCV<br>numpy<br>imutils<br>MediaPipe<br>PiCamera2<br>CircuitPython (Adafruit_Blinka)<br>Adafruit_NeoPixel
            </p>
          </div>
        </div>
        <a href="https://github.com/zcoakley/look-alike-droid" class="u-border-5 u-border-grey-75 u-border-hover-grey-50 u-btn u-btn-round u-button-style u-custom-font u-font-ubuntu u-hover-palette-1-light-1 u-palette-1-base u-radius u-text-hover-grey-5 u-text-white u-btn-1" target="_blank">GITHUB </a>
      </div>
    </section>
    
    
    
    <footer class="u-align-center u-clearfix u-container-align-center u-footer u-grey-80 u-footer" id="sec-1518"><div class="u-clearfix u-sheet u-sheet-1"></div></footer>
    <section class="u-backlink u-clearfix u-grey-80">
      <p class="u-text">
        <span>This site was created with the </span>
        <a class="u-link" href="https://nicepage.com/" target="_blank" rel="nofollow">
          <span>Nicepage</span>
        </a>
      </p>
    </section>
  
</body></html>